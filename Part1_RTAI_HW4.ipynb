{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Part1_RTAI_HW4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOCyYVPLPfPaKHTx9y9Ky2J",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0d91c2022e224729bf8cbaa2a6a0986d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_860521ce95fd42f9b2caab5ee7004b4c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c7c689cf896e4311957b9c0e2cd8d182",
              "IPY_MODEL_d64155a90428479c939d548f681b8dfd"
            ]
          }
        },
        "860521ce95fd42f9b2caab5ee7004b4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c7c689cf896e4311957b9c0e2cd8d182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cd1ca3be6b324bde9f0a8b4bf3221bf9",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8ae9d13d926244d8ba4366b6f7bb60ed"
          }
        },
        "d64155a90428479c939d548f681b8dfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1cc68afac4644334aa2116f95e11d0a4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [03:02&lt;00:00, 933924.92it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a5cda026b624fbe97ee7a62622416e8"
          }
        },
        "cd1ca3be6b324bde9f0a8b4bf3221bf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8ae9d13d926244d8ba4366b6f7bb60ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1cc68afac4644334aa2116f95e11d0a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a5cda026b624fbe97ee7a62622416e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ZachZaleski/ECGR-4090/blob/main/Part1_RTAI_HW4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ks0b6nl42ux4",
        "outputId": "5ff3b2db-609a-4c1f-a2c0-c11dc1110535"
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "torch.set_printoptions(edgeitems=2)\n",
        "torch.manual_seed(123)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f8f8275f730>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8AGrHPXR3VLY"
      },
      "source": [
        "class_names = ['airplane','automobile','bird','cat','deer',\n",
        "               'dog','frog','horse','ship','truck']"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 100,
          "referenced_widgets": [
            "0d91c2022e224729bf8cbaa2a6a0986d",
            "860521ce95fd42f9b2caab5ee7004b4c",
            "c7c689cf896e4311957b9c0e2cd8d182",
            "d64155a90428479c939d548f681b8dfd",
            "cd1ca3be6b324bde9f0a8b4bf3221bf9",
            "8ae9d13d926244d8ba4366b6f7bb60ed",
            "1cc68afac4644334aa2116f95e11d0a4",
            "4a5cda026b624fbe97ee7a62622416e8"
          ]
        },
        "id": "Wx-BNys23crE",
        "outputId": "dcc7dba9-d9c7-4771-babb-0cbde23a9050"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "cifar10 = datasets.CIFAR10(\n",
        "    'data', train=True, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d91c2022e224729bf8cbaa2a6a0986d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=170498071.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting data/cifar-10-python.tar.gz to data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e8-czFg3out",
        "outputId": "b53eef63-00dc-49f3-852c-165850f75f9d"
      },
      "source": [
        "cifar10_val = datasets.CIFAR10(\n",
        "    'data', train=False, download=True,\n",
        "    transform=transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4915, 0.4823, 0.4468),\n",
        "                             (0.2470, 0.2435, 0.2616))\n",
        "    ]))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlaqSXzQ3ww4"
      },
      "source": [
        "label_map = {6:0, 9: 1}\n",
        "class_names = ['frog', 'horse', 'ship', 'truck']\n",
        "cifar2 = [(img, label_map[label])\n",
        "          for img, label in cifar10 \n",
        "          if label in [6, 9]]\n",
        "cifar2_val = [(img, label_map[label])\n",
        "              for img, label in cifar10_val\n",
        "              if label in [6, 9]]"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbVcsoeF34F-"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "n_out = 2\n",
        "\n",
        "model = nn.Sequential(\n",
        "            nn.Linear(\n",
        "                3072,  # <1>\n",
        "                512,   # <2>\n",
        "            ),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(\n",
        "                512,   # <2>\n",
        "                n_out, # <3>\n",
        "            )\n",
        "        )"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41BnJ7lG37o-"
      },
      "source": [
        "def softmax(x):\n",
        "    return torch.exp(x) / torch.exp(x).sum()"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP6SPp3l370z",
        "outputId": "9a47406b-dfba-4164-c973-95ec29131eac"
      },
      "source": [
        "x = torch.tensor([1.0, 2.0, 3.0])\n",
        "\n",
        "softmax(x)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0900, 0.2447, 0.6652])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "edAFbq2O4GRy",
        "outputId": "7a180536-fdb8-4f44-8cbb-2e9933081e6b"
      },
      "source": [
        "softmax(x).sum()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(1.)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_VxEUsJ4KdZ",
        "outputId": "416abb9f-abdf-43a0-b4ac-8b5d859460f1"
      },
      "source": [
        "softmax = nn.Softmax(dim=1)\n",
        "\n",
        "x = torch.tensor([[1.0, 2.0, 3.0],\n",
        "                  [1.0, 2.0, 3.0]])\n",
        "\n",
        "softmax(x)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0900, 0.2447, 0.6652],\n",
              "        [0.0900, 0.2447, 0.6652]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EOdGlTrl4OiT"
      },
      "source": [
        "model = nn.Sequential(\n",
        "            nn.Linear(3072, 512),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(512, 2),\n",
        "            nn.Softmax(dim=1))"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "YUn1aIzr4Tpk",
        "outputId": "635a3d36-1991-4a29-d411-62157179c3cb"
      },
      "source": [
        "img, _ = cifar2[0]\n",
        "\n",
        "plt.imshow(img.permute(1, 2, 0))\n",
        "plt.show()"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96e8yhwT4WnO"
      },
      "source": [
        "img_batch = img.view(-1).unsqueeze(0)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTlB4n6m4aTI",
        "outputId": "0ff02888-f641-4e53-a285-deb99e726d18"
      },
      "source": [
        "out = model(img_batch)\n",
        "out"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.4784, 0.5216]], grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfjzHa0L4dE7",
        "outputId": "dc236179-bb57-4753-9b28-bc5dc3c356b7"
      },
      "source": [
        "_, index = torch.max(out, dim=1)\n",
        "\n",
        "index"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6STsLDBf4fwB",
        "outputId": "92b80dcf-5281-4e12-a366-9f8aa9d94261"
      },
      "source": [
        "out = torch.tensor([\n",
        "    [0.6, 0.4],\n",
        "    [0.9, 0.1],\n",
        "    [0.3, 0.7],\n",
        "    [0.2, 0.8],\n",
        "])\n",
        "class_index = torch.tensor([0, 0, 1, 1]).unsqueeze(1)\n",
        "\n",
        "truth = torch.zeros((4,2))\n",
        "truth.scatter_(dim=1, index=class_index, value=1.0)\n",
        "truth"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0.],\n",
              "        [1., 0.],\n",
              "        [0., 1.],\n",
              "        [0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gErrtT5Y8pLL",
        "outputId": "4509a45e-67ab-411e-90a0-66fb2f4c2d1f"
      },
      "source": [
        "def mse(out):\n",
        "    return ((out - truth) ** 2).sum(dim=1).mean()\n",
        "mse(out)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.1500)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PbnnsaSv8sGt",
        "outputId": "d10e839c-8452-4b53-b909-501afb84a5d7"
      },
      "source": [
        "out.gather(dim=1, index=class_index)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6000],\n",
              "        [0.9000],\n",
              "        [0.7000],\n",
              "        [0.8000]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S5Hw2UZr8w3V",
        "outputId": "21093a7f-d562-4e5c-ecd4-1dd98fcc41cb"
      },
      "source": [
        "def likelihood(out):\n",
        "    prod = 1.0\n",
        "    for x in out.gather(dim=1, index=class_index):\n",
        "        prod *= x\n",
        "    return prod\n",
        "\n",
        "likelihood(out)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.3024])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JU9xP4aD80Cy",
        "outputId": "421864f7-103a-4245-8dbd-0eb0bfcad604"
      },
      "source": [
        "def neg_log_likelihood(out):\n",
        "    return -likelihood(out).log()\n",
        "\n",
        "neg_log_likelihood(out)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.1960])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ixxUcrH_83CO",
        "outputId": "cf2e5367-94b1-4f7b-cb8c-e7256d71c2b3"
      },
      "source": [
        "out0 = out.clone().detach()\n",
        "out0[0] = torch.tensor([0.9, 0.1]) # more right\n",
        "\n",
        "out2 = out.clone().detach()\n",
        "out2[0] = torch.tensor([0.4, 0.6]) # slightly wrong\n",
        "\n",
        "out3 = out.clone().detach()\n",
        "out3[0] = torch.tensor([0.1, 0.9]) # very wrong\n",
        "\n",
        "mse_comparison = torch.tensor([mse(o) for o in [out0, out, out2, out3]])\n",
        "mse_comparison"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0750, 0.1500, 0.2500, 0.4750])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mE57CPEy85wn",
        "outputId": "258e6fac-08aa-427a-badb-21795d6e917a"
      },
      "source": [
        "((mse_comparison / mse_comparison[1]) - 1) * 100"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-50.0000,   0.0000,  66.6667, 216.6667])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xg9fTfke881D",
        "outputId": "39b27581-23df-4d4e-d103-55dac82f7cd4"
      },
      "source": [
        "nll_comparison = torch.tensor([neg_log_likelihood(o) \n",
        "                               for o in [out0, out, out2, out3]])\n",
        "nll_comparison"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.7905, 1.1960, 1.6015, 2.9878])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IYypSEzW8_zX",
        "outputId": "31fc67af-4628-48f3-c135-855b9451b93e"
      },
      "source": [
        "((nll_comparison / nll_comparison[1]) - 1) * 100"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-33.9016,   0.0000,  33.9016, 149.8121])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pQL4mlz29C_w",
        "outputId": "cc525cec-bd26-455b-c3ab-dd2d5a64a6d0"
      },
      "source": [
        "softmax = nn.Softmax(dim=1)\n",
        "\n",
        "log_softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "x = torch.tensor([[0.0, 104.0]])\n",
        "\n",
        "softmax(x)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lh8P9V1b9F9I",
        "outputId": "4ba7867c-deab-439f-8b20-e1abf086b6e1"
      },
      "source": [
        "softmax = nn.Softmax(dim=1)\n",
        "\n",
        "log_softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "x = torch.tensor([[0.0, 104.0]])\n",
        "\n",
        "softmax(x)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gyjjV8yN9Jyr",
        "outputId": "e3a9cdf6-4650-4e50-cedf-00c0dbff900f"
      },
      "source": [
        "torch.log(softmax(x))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-inf, 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05l0Ydpv9NA7",
        "outputId": "b6d54d65-9408-4805-d08f-de77972efc53"
      },
      "source": [
        "log_softmax(x)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-104.,    0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9otJT_hP9PaG",
        "outputId": "42fc024c-0a32-4fee-a46e-fd62e602b0d8"
      },
      "source": [
        "torch.exp(log_softmax(x))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oDHAg1IP9R_o"
      },
      "source": [
        "model = nn.Sequential(\n",
        "            nn.Linear(3072, 512),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(512, 2),\n",
        "            nn.LogSoftmax(dim=1))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxuUN56G9Vti"
      },
      "source": [
        "loss = nn.NLLLoss()"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lglk6J4e9bkh",
        "outputId": "98ba3a1d-f1bc-4f8f-b412-3793f30e72ac"
      },
      "source": [
        "img, label = cifar2[0]\n",
        "\n",
        "out = model(img.view(-1).unsqueeze(0))\n",
        "\n",
        "loss(out, torch.tensor([label]))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.5077, grad_fn=<NllLossBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHfN3p_19fSk",
        "outputId": "67a83f21-5bec-4c06-a795-3104f3206858"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "model = nn.Sequential(\n",
        "            nn.Linear(3072, 512),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(512, 2),\n",
        "            nn.LogSoftmax(dim=1))\n",
        "\n",
        "learning_rate = 1e-2\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "loss_fn = nn.NLLLoss()\n",
        "\n",
        "n_epochs = 200\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for img, label in cifar2:\n",
        "        out = model(img.view(-1).unsqueeze(0))\n",
        "        loss = loss_fn(out, torch.tensor([label]))\n",
        "                \n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss: 4.854689\n",
            "Epoch: 1, Loss: 4.496308\n",
            "Epoch: 2, Loss: 1.698532\n",
            "Epoch: 3, Loss: 6.565901\n",
            "Epoch: 4, Loss: 9.524979\n",
            "Epoch: 5, Loss: 6.006360\n",
            "Epoch: 6, Loss: 5.335664\n",
            "Epoch: 7, Loss: 13.375288\n",
            "Epoch: 8, Loss: 1.479551\n",
            "Epoch: 9, Loss: 2.397843\n",
            "Epoch: 10, Loss: 4.263307\n",
            "Epoch: 11, Loss: 6.935426\n",
            "Epoch: 12, Loss: 14.914207\n",
            "Epoch: 13, Loss: 0.002580\n",
            "Epoch: 14, Loss: 7.726982\n",
            "Epoch: 15, Loss: 0.077731\n",
            "Epoch: 16, Loss: 0.378323\n",
            "Epoch: 17, Loss: 8.452645\n",
            "Epoch: 18, Loss: 2.489220\n",
            "Epoch: 19, Loss: 4.116791\n",
            "Epoch: 20, Loss: 1.715885\n",
            "Epoch: 21, Loss: 3.215723\n",
            "Epoch: 22, Loss: 2.981966\n",
            "Epoch: 23, Loss: 6.080756\n",
            "Epoch: 24, Loss: 0.744871\n",
            "Epoch: 25, Loss: 5.307116\n",
            "Epoch: 26, Loss: 11.053152\n",
            "Epoch: 27, Loss: 0.320726\n",
            "Epoch: 28, Loss: 6.800272\n",
            "Epoch: 29, Loss: 7.307101\n",
            "Epoch: 30, Loss: 4.908613\n",
            "Epoch: 31, Loss: 4.487743\n",
            "Epoch: 32, Loss: 7.859955\n",
            "Epoch: 33, Loss: 3.328586\n",
            "Epoch: 34, Loss: 0.017713\n",
            "Epoch: 35, Loss: 0.126035\n",
            "Epoch: 36, Loss: 4.639104\n",
            "Epoch: 37, Loss: 8.709373\n",
            "Epoch: 38, Loss: 7.512465\n",
            "Epoch: 39, Loss: 21.558365\n",
            "Epoch: 40, Loss: 3.348360\n",
            "Epoch: 41, Loss: 13.174192\n",
            "Epoch: 42, Loss: 10.078793\n",
            "Epoch: 43, Loss: 4.939662\n",
            "Epoch: 44, Loss: 12.816634\n",
            "Epoch: 45, Loss: 11.997728\n",
            "Epoch: 46, Loss: 14.094867\n",
            "Epoch: 47, Loss: 21.536106\n",
            "Epoch: 48, Loss: 12.344878\n",
            "Epoch: 49, Loss: 24.504993\n",
            "Epoch: 50, Loss: 19.301096\n",
            "Epoch: 51, Loss: 18.528507\n",
            "Epoch: 52, Loss: 23.069479\n",
            "Epoch: 53, Loss: 29.826920\n",
            "Epoch: 54, Loss: 7.280510\n",
            "Epoch: 55, Loss: 4.424743\n",
            "Epoch: 56, Loss: 5.940241\n",
            "Epoch: 57, Loss: 15.650886\n",
            "Epoch: 58, Loss: 5.241889\n",
            "Epoch: 59, Loss: 16.782295\n",
            "Epoch: 60, Loss: 4.473853\n",
            "Epoch: 61, Loss: 4.147499\n",
            "Epoch: 62, Loss: 12.420807\n",
            "Epoch: 63, Loss: 9.956139\n",
            "Epoch: 64, Loss: 20.899052\n",
            "Epoch: 65, Loss: 13.657265\n",
            "Epoch: 66, Loss: 11.769188\n",
            "Epoch: 67, Loss: 18.048994\n",
            "Epoch: 68, Loss: 5.460102\n",
            "Epoch: 69, Loss: 7.438613\n",
            "Epoch: 70, Loss: 9.023014\n",
            "Epoch: 71, Loss: 8.860500\n",
            "Epoch: 72, Loss: 5.212415\n",
            "Epoch: 73, Loss: 2.285508\n",
            "Epoch: 74, Loss: 11.433455\n",
            "Epoch: 75, Loss: 3.742763\n",
            "Epoch: 76, Loss: 4.162246\n",
            "Epoch: 77, Loss: 1.340157\n",
            "Epoch: 78, Loss: 6.114191\n",
            "Epoch: 79, Loss: 11.558096\n",
            "Epoch: 80, Loss: 1.006340\n",
            "Epoch: 81, Loss: 15.160353\n",
            "Epoch: 82, Loss: 15.504143\n",
            "Epoch: 83, Loss: 0.775351\n",
            "Epoch: 84, Loss: 3.732157\n",
            "Epoch: 85, Loss: 1.257188\n",
            "Epoch: 86, Loss: 4.216252\n",
            "Epoch: 87, Loss: 11.122552\n",
            "Epoch: 88, Loss: 25.854645\n",
            "Epoch: 89, Loss: 18.933647\n",
            "Epoch: 90, Loss: 7.616335\n",
            "Epoch: 91, Loss: 10.688189\n",
            "Epoch: 92, Loss: 22.504227\n",
            "Epoch: 93, Loss: 27.725714\n",
            "Epoch: 94, Loss: 8.873783\n",
            "Epoch: 95, Loss: 1.858146\n",
            "Epoch: 96, Loss: 15.489026\n",
            "Epoch: 97, Loss: 16.095188\n",
            "Epoch: 98, Loss: 16.164154\n",
            "Epoch: 99, Loss: 34.332970\n",
            "Epoch: 100, Loss: 24.525362\n",
            "Epoch: 101, Loss: 17.759552\n",
            "Epoch: 102, Loss: 17.287340\n",
            "Epoch: 103, Loss: 31.752117\n",
            "Epoch: 104, Loss: 17.974655\n",
            "Epoch: 105, Loss: 1.392432\n",
            "Epoch: 106, Loss: 10.653440\n",
            "Epoch: 107, Loss: 1.689841\n",
            "Epoch: 108, Loss: 10.228102\n",
            "Epoch: 109, Loss: 14.757832\n",
            "Epoch: 110, Loss: 21.093390\n",
            "Epoch: 111, Loss: 16.492950\n",
            "Epoch: 112, Loss: 8.682028\n",
            "Epoch: 113, Loss: 2.755754\n",
            "Epoch: 114, Loss: 2.454528\n",
            "Epoch: 115, Loss: 26.082306\n",
            "Epoch: 116, Loss: 17.398285\n",
            "Epoch: 117, Loss: 4.689731\n",
            "Epoch: 118, Loss: 6.250017\n",
            "Epoch: 119, Loss: 4.067413\n",
            "Epoch: 120, Loss: 6.935403\n",
            "Epoch: 121, Loss: 9.808395\n",
            "Epoch: 122, Loss: 8.885015\n",
            "Epoch: 123, Loss: 13.848456\n",
            "Epoch: 124, Loss: 10.660129\n",
            "Epoch: 125, Loss: 6.907487\n",
            "Epoch: 126, Loss: 8.060255\n",
            "Epoch: 127, Loss: 10.895801\n",
            "Epoch: 128, Loss: 9.204949\n",
            "Epoch: 129, Loss: 5.158420\n",
            "Epoch: 130, Loss: 8.870389\n",
            "Epoch: 131, Loss: 13.091129\n",
            "Epoch: 132, Loss: 7.336490\n",
            "Epoch: 133, Loss: 18.269835\n",
            "Epoch: 134, Loss: 18.790365\n",
            "Epoch: 135, Loss: 6.480450\n",
            "Epoch: 136, Loss: 10.859032\n",
            "Epoch: 137, Loss: 1.705636\n",
            "Epoch: 138, Loss: 11.867435\n",
            "Epoch: 139, Loss: 9.941246\n",
            "Epoch: 140, Loss: 6.750897\n",
            "Epoch: 141, Loss: 10.021216\n",
            "Epoch: 142, Loss: 6.648156\n",
            "Epoch: 143, Loss: 6.865256\n",
            "Epoch: 144, Loss: 17.142265\n",
            "Epoch: 145, Loss: 17.580624\n",
            "Epoch: 146, Loss: 22.909023\n",
            "Epoch: 147, Loss: 13.827564\n",
            "Epoch: 148, Loss: 18.248039\n",
            "Epoch: 149, Loss: 13.896596\n",
            "Epoch: 150, Loss: 14.424981\n",
            "Epoch: 151, Loss: 13.580701\n",
            "Epoch: 152, Loss: 8.877664\n",
            "Epoch: 153, Loss: 10.608614\n",
            "Epoch: 154, Loss: 17.009031\n",
            "Epoch: 155, Loss: 13.398893\n",
            "Epoch: 156, Loss: 12.287671\n",
            "Epoch: 157, Loss: 2.688485\n",
            "Epoch: 158, Loss: 15.062577\n",
            "Epoch: 159, Loss: 4.359710\n",
            "Epoch: 160, Loss: 16.252605\n",
            "Epoch: 161, Loss: 16.674194\n",
            "Epoch: 162, Loss: 17.907703\n",
            "Epoch: 163, Loss: 12.710340\n",
            "Epoch: 164, Loss: 16.791992\n",
            "Epoch: 165, Loss: 2.782816\n",
            "Epoch: 166, Loss: 9.152162\n",
            "Epoch: 167, Loss: 9.759839\n",
            "Epoch: 168, Loss: 8.312554\n",
            "Epoch: 169, Loss: 7.984804\n",
            "Epoch: 170, Loss: 14.492868\n",
            "Epoch: 171, Loss: 14.243538\n",
            "Epoch: 172, Loss: 18.745699\n",
            "Epoch: 173, Loss: 12.029509\n",
            "Epoch: 174, Loss: 15.535461\n",
            "Epoch: 175, Loss: 20.799137\n",
            "Epoch: 176, Loss: 13.749465\n",
            "Epoch: 177, Loss: 11.248846\n",
            "Epoch: 178, Loss: 8.918121\n",
            "Epoch: 179, Loss: 14.224037\n",
            "Epoch: 180, Loss: 11.873883\n",
            "Epoch: 181, Loss: 12.143000\n",
            "Epoch: 182, Loss: 3.729229\n",
            "Epoch: 183, Loss: 2.775570\n",
            "Epoch: 184, Loss: 5.248294\n",
            "Epoch: 185, Loss: 0.927285\n",
            "Epoch: 186, Loss: 7.663414\n",
            "Epoch: 187, Loss: 3.617827\n",
            "Epoch: 188, Loss: 5.072706\n",
            "Epoch: 189, Loss: 12.764334\n",
            "Epoch: 190, Loss: 5.311516\n",
            "Epoch: 191, Loss: 5.715954\n",
            "Epoch: 192, Loss: 3.162414\n",
            "Epoch: 193, Loss: 5.951426\n",
            "Epoch: 194, Loss: 19.820946\n",
            "Epoch: 195, Loss: 7.712142\n",
            "Epoch: 196, Loss: 6.598442\n",
            "Epoch: 197, Loss: 11.987037\n",
            "Epoch: 198, Loss: 13.495294\n",
            "Epoch: 199, Loss: 4.058495\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qplijjzzuXgK",
        "outputId": "2b7a1ce2-d697-410c-be76-4170d31d5184"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=True)\n",
        "\n",
        "model = nn.Sequential(\n",
        "            nn.Linear(3072, 128),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(128, 4),\n",
        "            nn.LogSoftmax(dim=1))\n",
        "\n",
        "learning_rate = 1e-2\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "loss_fn = nn.NLLLoss()\n",
        "\n",
        "n_epochs = 200\n",
        "\n",
        "t0 = time.time()\n",
        "for epoch in range(n_epochs):\n",
        "    for imgs, labels in train_loader:\n",
        "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
        "\n",
        "t1 = time.time()\n",
        "TotalTime = t1 - t0\n",
        "print(\"Total time: \", TotalTime)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss: 0.384462\n",
            "Epoch: 1, Loss: 0.353788\n",
            "Epoch: 2, Loss: 0.200041\n",
            "Epoch: 3, Loss: 0.156123\n",
            "Epoch: 4, Loss: 0.426598\n",
            "Epoch: 5, Loss: 0.261545\n",
            "Epoch: 6, Loss: 0.090307\n",
            "Epoch: 7, Loss: 0.096493\n",
            "Epoch: 8, Loss: 0.485101\n",
            "Epoch: 9, Loss: 0.098792\n",
            "Epoch: 10, Loss: 0.166920\n",
            "Epoch: 11, Loss: 0.047117\n",
            "Epoch: 12, Loss: 0.087907\n",
            "Epoch: 13, Loss: 0.068003\n",
            "Epoch: 14, Loss: 0.099627\n",
            "Epoch: 15, Loss: 0.272643\n",
            "Epoch: 16, Loss: 0.273304\n",
            "Epoch: 17, Loss: 0.085520\n",
            "Epoch: 18, Loss: 0.036159\n",
            "Epoch: 19, Loss: 0.161434\n",
            "Epoch: 20, Loss: 0.252739\n",
            "Epoch: 21, Loss: 0.284020\n",
            "Epoch: 22, Loss: 0.164493\n",
            "Epoch: 23, Loss: 0.052477\n",
            "Epoch: 24, Loss: 0.170513\n",
            "Epoch: 25, Loss: 0.139089\n",
            "Epoch: 26, Loss: 0.078529\n",
            "Epoch: 27, Loss: 0.109175\n",
            "Epoch: 28, Loss: 0.016699\n",
            "Epoch: 29, Loss: 0.078620\n",
            "Epoch: 30, Loss: 0.049674\n",
            "Epoch: 31, Loss: 0.061634\n",
            "Epoch: 32, Loss: 0.021411\n",
            "Epoch: 33, Loss: 0.083561\n",
            "Epoch: 34, Loss: 0.065011\n",
            "Epoch: 35, Loss: 0.124322\n",
            "Epoch: 36, Loss: 0.095827\n",
            "Epoch: 37, Loss: 0.026431\n",
            "Epoch: 38, Loss: 0.037951\n",
            "Epoch: 39, Loss: 0.014600\n",
            "Epoch: 40, Loss: 0.015586\n",
            "Epoch: 41, Loss: 0.009147\n",
            "Epoch: 42, Loss: 0.051215\n",
            "Epoch: 43, Loss: 0.010537\n",
            "Epoch: 44, Loss: 0.014129\n",
            "Epoch: 45, Loss: 0.019660\n",
            "Epoch: 46, Loss: 0.039018\n",
            "Epoch: 47, Loss: 0.019601\n",
            "Epoch: 48, Loss: 0.051590\n",
            "Epoch: 49, Loss: 0.034472\n",
            "Epoch: 50, Loss: 0.036011\n",
            "Epoch: 51, Loss: 0.138699\n",
            "Epoch: 52, Loss: 0.006335\n",
            "Epoch: 53, Loss: 0.008626\n",
            "Epoch: 54, Loss: 0.042714\n",
            "Epoch: 55, Loss: 0.010207\n",
            "Epoch: 56, Loss: 0.008298\n",
            "Epoch: 57, Loss: 0.030345\n",
            "Epoch: 58, Loss: 0.010932\n",
            "Epoch: 59, Loss: 0.028480\n",
            "Epoch: 60, Loss: 0.022657\n",
            "Epoch: 61, Loss: 0.016596\n",
            "Epoch: 62, Loss: 0.023493\n",
            "Epoch: 63, Loss: 0.010029\n",
            "Epoch: 64, Loss: 0.017341\n",
            "Epoch: 65, Loss: 0.009590\n",
            "Epoch: 66, Loss: 0.030101\n",
            "Epoch: 67, Loss: 0.007946\n",
            "Epoch: 68, Loss: 0.005390\n",
            "Epoch: 69, Loss: 0.016914\n",
            "Epoch: 70, Loss: 0.019125\n",
            "Epoch: 71, Loss: 0.016150\n",
            "Epoch: 72, Loss: 0.017219\n",
            "Epoch: 73, Loss: 0.013419\n",
            "Epoch: 74, Loss: 0.009584\n",
            "Epoch: 75, Loss: 0.014634\n",
            "Epoch: 76, Loss: 0.013139\n",
            "Epoch: 77, Loss: 0.017656\n",
            "Epoch: 78, Loss: 0.010174\n",
            "Epoch: 79, Loss: 0.005733\n",
            "Epoch: 80, Loss: 0.017162\n",
            "Epoch: 81, Loss: 0.010015\n",
            "Epoch: 82, Loss: 0.015776\n",
            "Epoch: 83, Loss: 0.007818\n",
            "Epoch: 84, Loss: 0.023083\n",
            "Epoch: 85, Loss: 0.012268\n",
            "Epoch: 86, Loss: 0.003554\n",
            "Epoch: 87, Loss: 0.004912\n",
            "Epoch: 88, Loss: 0.010509\n",
            "Epoch: 89, Loss: 0.015973\n",
            "Epoch: 90, Loss: 0.006117\n",
            "Epoch: 91, Loss: 0.004276\n",
            "Epoch: 92, Loss: 0.005808\n",
            "Epoch: 93, Loss: 0.016086\n",
            "Epoch: 94, Loss: 0.005355\n",
            "Epoch: 95, Loss: 0.010333\n",
            "Epoch: 96, Loss: 0.006617\n",
            "Epoch: 97, Loss: 0.006781\n",
            "Epoch: 98, Loss: 0.001760\n",
            "Epoch: 99, Loss: 0.011789\n",
            "Epoch: 100, Loss: 0.014124\n",
            "Epoch: 101, Loss: 0.001340\n",
            "Epoch: 102, Loss: 0.004790\n",
            "Epoch: 103, Loss: 0.003913\n",
            "Epoch: 104, Loss: 0.006937\n",
            "Epoch: 105, Loss: 0.007088\n",
            "Epoch: 106, Loss: 0.004190\n",
            "Epoch: 107, Loss: 0.007803\n",
            "Epoch: 108, Loss: 0.003741\n",
            "Epoch: 109, Loss: 0.006152\n",
            "Epoch: 110, Loss: 0.002232\n",
            "Epoch: 111, Loss: 0.001615\n",
            "Epoch: 112, Loss: 0.003706\n",
            "Epoch: 113, Loss: 0.010478\n",
            "Epoch: 114, Loss: 0.007822\n",
            "Epoch: 115, Loss: 0.004412\n",
            "Epoch: 116, Loss: 0.001761\n",
            "Epoch: 117, Loss: 0.005042\n",
            "Epoch: 118, Loss: 0.002269\n",
            "Epoch: 119, Loss: 0.003206\n",
            "Epoch: 120, Loss: 0.011418\n",
            "Epoch: 121, Loss: 0.004761\n",
            "Epoch: 122, Loss: 0.003674\n",
            "Epoch: 123, Loss: 0.005634\n",
            "Epoch: 124, Loss: 0.006556\n",
            "Epoch: 125, Loss: 0.006405\n",
            "Epoch: 126, Loss: 0.005489\n",
            "Epoch: 127, Loss: 0.006837\n",
            "Epoch: 128, Loss: 0.001797\n",
            "Epoch: 129, Loss: 0.003294\n",
            "Epoch: 130, Loss: 0.003892\n",
            "Epoch: 131, Loss: 0.004652\n",
            "Epoch: 132, Loss: 0.002967\n",
            "Epoch: 133, Loss: 0.004974\n",
            "Epoch: 134, Loss: 0.004173\n",
            "Epoch: 135, Loss: 0.001751\n",
            "Epoch: 136, Loss: 0.007342\n",
            "Epoch: 137, Loss: 0.004892\n",
            "Epoch: 138, Loss: 0.001340\n",
            "Epoch: 139, Loss: 0.004318\n",
            "Epoch: 140, Loss: 0.007558\n",
            "Epoch: 141, Loss: 0.002512\n",
            "Epoch: 142, Loss: 0.002764\n",
            "Epoch: 143, Loss: 0.001457\n",
            "Epoch: 144, Loss: 0.004741\n",
            "Epoch: 145, Loss: 0.002249\n",
            "Epoch: 146, Loss: 0.003015\n",
            "Epoch: 147, Loss: 0.002663\n",
            "Epoch: 148, Loss: 0.004262\n",
            "Epoch: 149, Loss: 0.002375\n",
            "Epoch: 150, Loss: 0.002640\n",
            "Epoch: 151, Loss: 0.006687\n",
            "Epoch: 152, Loss: 0.001820\n",
            "Epoch: 153, Loss: 0.005151\n",
            "Epoch: 154, Loss: 0.002887\n",
            "Epoch: 155, Loss: 0.001416\n",
            "Epoch: 156, Loss: 0.001382\n",
            "Epoch: 157, Loss: 0.002434\n",
            "Epoch: 158, Loss: 0.002753\n",
            "Epoch: 159, Loss: 0.002172\n",
            "Epoch: 160, Loss: 0.001967\n",
            "Epoch: 161, Loss: 0.007507\n",
            "Epoch: 162, Loss: 0.003174\n",
            "Epoch: 163, Loss: 0.004314\n",
            "Epoch: 164, Loss: 0.001731\n",
            "Epoch: 165, Loss: 0.003423\n",
            "Epoch: 166, Loss: 0.004637\n",
            "Epoch: 167, Loss: 0.000992\n",
            "Epoch: 168, Loss: 0.005392\n",
            "Epoch: 169, Loss: 0.004725\n",
            "Epoch: 170, Loss: 0.002296\n",
            "Epoch: 171, Loss: 0.002560\n",
            "Epoch: 172, Loss: 0.006379\n",
            "Epoch: 173, Loss: 0.004643\n",
            "Epoch: 174, Loss: 0.002912\n",
            "Epoch: 175, Loss: 0.003793\n",
            "Epoch: 176, Loss: 0.003991\n",
            "Epoch: 177, Loss: 0.001386\n",
            "Epoch: 178, Loss: 0.001546\n",
            "Epoch: 179, Loss: 0.002388\n",
            "Epoch: 180, Loss: 0.002371\n",
            "Epoch: 181, Loss: 0.006490\n",
            "Epoch: 182, Loss: 0.003100\n",
            "Epoch: 183, Loss: 0.005748\n",
            "Epoch: 184, Loss: 0.001572\n",
            "Epoch: 185, Loss: 0.001861\n",
            "Epoch: 186, Loss: 0.000566\n",
            "Epoch: 187, Loss: 0.004396\n",
            "Epoch: 188, Loss: 0.000563\n",
            "Epoch: 189, Loss: 0.001587\n",
            "Epoch: 190, Loss: 0.001479\n",
            "Epoch: 191, Loss: 0.004417\n",
            "Epoch: 192, Loss: 0.001206\n",
            "Epoch: 193, Loss: 0.000828\n",
            "Epoch: 194, Loss: 0.001556\n",
            "Epoch: 195, Loss: 0.001696\n",
            "Epoch: 196, Loss: 0.001217\n",
            "Epoch: 197, Loss: 0.002200\n",
            "Epoch: 198, Loss: 0.001233\n",
            "Epoch: 199, Loss: 0.002716\n",
            "Total time:  136.49655556678772\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDZLDrp5Wp9-",
        "outputId": "6397e4b2-31f5-4530-dcdf-a91f7789dfe6"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import time\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(cifar2, batch_size=64,\n",
        "                                           shuffle=True)\n",
        "\n",
        "model = nn.Sequential(\n",
        "            nn.Linear(3072, 1024),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(1024, 512),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(512, 128),\n",
        "            nn.Tanh(),\n",
        "            nn.Linear(128, 4))\n",
        "\n",
        "learning_rate = 1e-2\n",
        "\n",
        "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "n_epochs = 200\n",
        "\n",
        "t2 = time.time()\n",
        "for epoch in range(n_epochs):\n",
        "    for imgs, labels in train_loader:\n",
        "        outputs = model(imgs.view(imgs.shape[0], -1))\n",
        "        loss = loss_fn(outputs, labels)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    print(\"Epoch: %d, Loss: %f\" % (epoch, float(loss)))\n",
        "\n",
        "t3 = time.time()\n",
        "TotalTime2 = t3 - t2\n",
        "\n",
        "print(\"Total Time \", TotalTime2)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0, Loss: 0.399629\n",
            "Epoch: 1, Loss: 0.245768\n",
            "Epoch: 2, Loss: 0.464472\n",
            "Epoch: 3, Loss: 0.286197\n",
            "Epoch: 4, Loss: 0.178700\n",
            "Epoch: 5, Loss: 0.389373\n",
            "Epoch: 6, Loss: 0.111758\n",
            "Epoch: 7, Loss: 0.285861\n",
            "Epoch: 8, Loss: 0.283264\n",
            "Epoch: 9, Loss: 0.105488\n",
            "Epoch: 10, Loss: 0.143113\n",
            "Epoch: 11, Loss: 0.118356\n",
            "Epoch: 12, Loss: 0.327182\n",
            "Epoch: 13, Loss: 0.195282\n",
            "Epoch: 14, Loss: 0.233161\n",
            "Epoch: 15, Loss: 0.555178\n",
            "Epoch: 16, Loss: 0.068058\n",
            "Epoch: 17, Loss: 0.226802\n",
            "Epoch: 18, Loss: 0.122006\n",
            "Epoch: 19, Loss: 0.478116\n",
            "Epoch: 20, Loss: 0.311386\n",
            "Epoch: 21, Loss: 0.102034\n",
            "Epoch: 22, Loss: 0.291841\n",
            "Epoch: 23, Loss: 0.154104\n",
            "Epoch: 24, Loss: 0.037736\n",
            "Epoch: 25, Loss: 0.071566\n",
            "Epoch: 26, Loss: 0.011297\n",
            "Epoch: 27, Loss: 0.007362\n",
            "Epoch: 28, Loss: 0.001962\n",
            "Epoch: 29, Loss: 0.026436\n",
            "Epoch: 30, Loss: 0.179711\n",
            "Epoch: 31, Loss: 0.010974\n",
            "Epoch: 32, Loss: 0.012241\n",
            "Epoch: 33, Loss: 0.005659\n",
            "Epoch: 34, Loss: 0.002868\n",
            "Epoch: 35, Loss: 0.011540\n",
            "Epoch: 36, Loss: 0.007471\n",
            "Epoch: 37, Loss: 0.020421\n",
            "Epoch: 38, Loss: 0.004149\n",
            "Epoch: 39, Loss: 0.002423\n",
            "Epoch: 40, Loss: 0.003521\n",
            "Epoch: 41, Loss: 0.000757\n",
            "Epoch: 42, Loss: 0.004979\n",
            "Epoch: 43, Loss: 0.010510\n",
            "Epoch: 44, Loss: 0.001487\n",
            "Epoch: 45, Loss: 0.007805\n",
            "Epoch: 46, Loss: 0.000865\n",
            "Epoch: 47, Loss: 0.003928\n",
            "Epoch: 48, Loss: 0.001083\n",
            "Epoch: 49, Loss: 0.001424\n",
            "Epoch: 50, Loss: 0.001462\n",
            "Epoch: 51, Loss: 0.000326\n",
            "Epoch: 52, Loss: 0.001946\n",
            "Epoch: 53, Loss: 0.001065\n",
            "Epoch: 54, Loss: 0.000310\n",
            "Epoch: 55, Loss: 0.001319\n",
            "Epoch: 56, Loss: 0.001071\n",
            "Epoch: 57, Loss: 0.000434\n",
            "Epoch: 58, Loss: 0.001962\n",
            "Epoch: 59, Loss: 0.000827\n",
            "Epoch: 60, Loss: 0.000497\n",
            "Epoch: 61, Loss: 0.000486\n",
            "Epoch: 62, Loss: 0.001555\n",
            "Epoch: 63, Loss: 0.001136\n",
            "Epoch: 64, Loss: 0.001024\n",
            "Epoch: 65, Loss: 0.001239\n",
            "Epoch: 66, Loss: 0.000541\n",
            "Epoch: 67, Loss: 0.000619\n",
            "Epoch: 68, Loss: 0.000379\n",
            "Epoch: 69, Loss: 0.000418\n",
            "Epoch: 70, Loss: 0.000629\n",
            "Epoch: 71, Loss: 0.000931\n",
            "Epoch: 72, Loss: 0.000721\n",
            "Epoch: 73, Loss: 0.000611\n",
            "Epoch: 74, Loss: 0.000629\n",
            "Epoch: 75, Loss: 0.001451\n",
            "Epoch: 76, Loss: 0.000422\n",
            "Epoch: 77, Loss: 0.000884\n",
            "Epoch: 78, Loss: 0.000836\n",
            "Epoch: 79, Loss: 0.000833\n",
            "Epoch: 80, Loss: 0.000285\n",
            "Epoch: 81, Loss: 0.000261\n",
            "Epoch: 82, Loss: 0.000565\n",
            "Epoch: 83, Loss: 0.000634\n",
            "Epoch: 84, Loss: 0.000109\n",
            "Epoch: 85, Loss: 0.000164\n",
            "Epoch: 86, Loss: 0.000493\n",
            "Epoch: 87, Loss: 0.000179\n",
            "Epoch: 88, Loss: 0.000957\n",
            "Epoch: 89, Loss: 0.000494\n",
            "Epoch: 90, Loss: 0.000604\n",
            "Epoch: 91, Loss: 0.001138\n",
            "Epoch: 92, Loss: 0.001128\n",
            "Epoch: 93, Loss: 0.000575\n",
            "Epoch: 94, Loss: 0.000260\n",
            "Epoch: 95, Loss: 0.000097\n",
            "Epoch: 96, Loss: 0.000574\n",
            "Epoch: 97, Loss: 0.000456\n",
            "Epoch: 98, Loss: 0.000397\n",
            "Epoch: 99, Loss: 0.000350\n",
            "Epoch: 100, Loss: 0.000506\n",
            "Epoch: 101, Loss: 0.000720\n",
            "Epoch: 102, Loss: 0.000379\n",
            "Epoch: 103, Loss: 0.000333\n",
            "Epoch: 104, Loss: 0.000193\n",
            "Epoch: 105, Loss: 0.000394\n",
            "Epoch: 106, Loss: 0.000288\n",
            "Epoch: 107, Loss: 0.000490\n",
            "Epoch: 108, Loss: 0.000367\n",
            "Epoch: 109, Loss: 0.000096\n",
            "Epoch: 110, Loss: 0.000520\n",
            "Epoch: 111, Loss: 0.000350\n",
            "Epoch: 112, Loss: 0.000140\n",
            "Epoch: 113, Loss: 0.000575\n",
            "Epoch: 114, Loss: 0.000322\n",
            "Epoch: 115, Loss: 0.000102\n",
            "Epoch: 116, Loss: 0.000248\n",
            "Epoch: 117, Loss: 0.000069\n",
            "Epoch: 118, Loss: 0.000653\n",
            "Epoch: 119, Loss: 0.000405\n",
            "Epoch: 120, Loss: 0.000538\n",
            "Epoch: 121, Loss: 0.000649\n",
            "Epoch: 122, Loss: 0.000159\n",
            "Epoch: 123, Loss: 0.000109\n",
            "Epoch: 124, Loss: 0.000973\n",
            "Epoch: 125, Loss: 0.000154\n",
            "Epoch: 126, Loss: 0.000250\n",
            "Epoch: 127, Loss: 0.000208\n",
            "Epoch: 128, Loss: 0.000156\n",
            "Epoch: 129, Loss: 0.000085\n",
            "Epoch: 130, Loss: 0.000755\n",
            "Epoch: 131, Loss: 0.000563\n",
            "Epoch: 132, Loss: 0.000205\n",
            "Epoch: 133, Loss: 0.000130\n",
            "Epoch: 134, Loss: 0.000259\n",
            "Epoch: 135, Loss: 0.000102\n",
            "Epoch: 136, Loss: 0.000133\n",
            "Epoch: 137, Loss: 0.000056\n",
            "Epoch: 138, Loss: 0.000255\n",
            "Epoch: 139, Loss: 0.000172\n",
            "Epoch: 140, Loss: 0.000990\n",
            "Epoch: 141, Loss: 0.000389\n",
            "Epoch: 142, Loss: 0.000103\n",
            "Epoch: 143, Loss: 0.000309\n",
            "Epoch: 144, Loss: 0.000229\n",
            "Epoch: 145, Loss: 0.000182\n",
            "Epoch: 146, Loss: 0.000317\n",
            "Epoch: 147, Loss: 0.000053\n",
            "Epoch: 148, Loss: 0.000373\n",
            "Epoch: 149, Loss: 0.000302\n",
            "Epoch: 150, Loss: 0.000038\n",
            "Epoch: 151, Loss: 0.000276\n",
            "Epoch: 152, Loss: 0.000171\n",
            "Epoch: 153, Loss: 0.000140\n",
            "Epoch: 154, Loss: 0.000116\n",
            "Epoch: 155, Loss: 0.000199\n",
            "Epoch: 156, Loss: 0.000101\n",
            "Epoch: 157, Loss: 0.000278\n",
            "Epoch: 158, Loss: 0.000186\n",
            "Epoch: 159, Loss: 0.000285\n",
            "Epoch: 160, Loss: 0.000482\n",
            "Epoch: 161, Loss: 0.000180\n",
            "Epoch: 162, Loss: 0.000041\n",
            "Epoch: 163, Loss: 0.000355\n",
            "Epoch: 164, Loss: 0.000285\n",
            "Epoch: 165, Loss: 0.000265\n",
            "Epoch: 166, Loss: 0.000185\n",
            "Epoch: 167, Loss: 0.000339\n",
            "Epoch: 168, Loss: 0.000127\n",
            "Epoch: 169, Loss: 0.000166\n",
            "Epoch: 170, Loss: 0.000255\n",
            "Epoch: 171, Loss: 0.000159\n",
            "Epoch: 172, Loss: 0.000245\n",
            "Epoch: 173, Loss: 0.000228\n",
            "Epoch: 174, Loss: 0.000127\n",
            "Epoch: 175, Loss: 0.000081\n",
            "Epoch: 176, Loss: 0.000286\n",
            "Epoch: 177, Loss: 0.000271\n",
            "Epoch: 178, Loss: 0.000053\n",
            "Epoch: 179, Loss: 0.000095\n",
            "Epoch: 180, Loss: 0.000172\n",
            "Epoch: 181, Loss: 0.000119\n",
            "Epoch: 182, Loss: 0.000485\n",
            "Epoch: 183, Loss: 0.000157\n",
            "Epoch: 184, Loss: 0.000164\n",
            "Epoch: 185, Loss: 0.000205\n",
            "Epoch: 186, Loss: 0.000079\n",
            "Epoch: 187, Loss: 0.000101\n",
            "Epoch: 188, Loss: 0.000186\n",
            "Epoch: 189, Loss: 0.000090\n",
            "Epoch: 190, Loss: 0.000200\n",
            "Epoch: 191, Loss: 0.000173\n",
            "Epoch: 192, Loss: 0.000175\n",
            "Epoch: 193, Loss: 0.000131\n",
            "Epoch: 194, Loss: 0.000224\n",
            "Epoch: 195, Loss: 0.000088\n",
            "Epoch: 196, Loss: 0.000210\n",
            "Epoch: 197, Loss: 0.000181\n",
            "Epoch: 198, Loss: 0.000032\n",
            "Epoch: 199, Loss: 0.000085\n",
            "Total Time  979.1875967979431\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}